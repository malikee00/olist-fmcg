# Phase 5 â€” Airflow Orchestration ğŸš€
Pseudo-Realtime | Incremental | Production-like 

## Why pseudo-realtime? â±ï¸
This project simulates near-real-time ingestion via file arrival in `incoming/`,
orchestrated by Airflow micro-batches. True streaming is out of scope because the source dataset is static. 

## DAG schedule ğŸ—“ï¸
- Runs every **10 minutes** (`*/10 * * * *`)
- Important: scheduling is **not** data generation.
  Airflow simply **checks** whether a new batch exists.

## Trigger mechanism (marker file) ğŸ·ï¸
A new batch is detected via marker files:
- `data/raw/olist/incoming/_BATCH_<id>.ready`

Why markers?
- Prevents partial upload issues 
- Avoids race conditions 
- Makes event simulation clear 

## Anti-duplicate guard ğŸ”
Airflow compares:
- **marker batch_id** (from `_BATCH_<id>.ready`)
vs
- **checkpoint**: `data/checkpoints/bronze_ingest_state.json` (`last_batch_id`)

Rules:
- No marker => **NO-OP success** 
- Marker exists but `batch_id == last_batch_id` => **NO-OP success** 
- Marker exists and `batch_id != last_batch_id` => run Phase 2 â†’ 3 â†’ 4 

This prevents accidental reruns and duplicate appends.

## Fail-fast gates âš¡
Airflow depends on exit codes from scripts:

| Script | Fails if |
|---|---|
| `run_phase2.ps1` | bronze validation fails |
| `run_phase3.ps1` | silver validation fails |
| `run_phase4.ps1` | gold validation fails |

Exit code contract:
- `0` â†’ continue âœ…
- `!= 0` â†’ DAG fails immediately âŒ

## DAG flow ğŸ§ 
`branch_on_marker_and_checkpoint`
- if no-op â†’ `t_noop` â†’ notify success âœ…
- else â†’ `t_phase2_bronze` â†’ `t_phase3_silver` â†’ `t_phase4_gold` â†’ notify success âœ…
- any failure â†’ notify failure âŒ

## Local development note ğŸªŸ
Local development uses **PowerShell** runners.
In Linux-based Airflow deployment, these scripts can be replaced with shell equivalents without changing pipeline logic.
